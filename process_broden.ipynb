{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for processing original broden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as im\n",
    "from PIL import Image\n",
    "import skimage\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import re\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'dataset/broden1_227/'\n",
    "index_frame = pd.read_csv(data_dir + 'index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks at label for each pixel and returns the most common label\n",
    "# Is this the best way to be doing things??? Who knows.\n",
    "def extract_prominent_feature(file):\n",
    "    img = skimage.io.imread(file)\n",
    "    features = np.add(img[:,:,0], 256 * img[:,:,1])\n",
    "    features = features.flatten()\n",
    "    features = features[features != 0]\n",
    "    features = np.bincount(features)\n",
    "    if features.size != 0:\n",
    "        return features.argmax()\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# returns a list of every features present in a feature image file\n",
    "def extract_features_from_file(file):\n",
    "    img = skimage.io.imread(file)\n",
    "    features = np.add(img[:,:,0], 256 * img[:,:,1])\n",
    "    features = features.flatten()\n",
    "    features = np.unique(features[features != 0])\n",
    "    return features\n",
    "\n",
    "categories = ['color', 'object', 'part', 'material', 'scene', 'texture']\n",
    "multi_label_pattern = re.compile(\"^\\w+(;\\w+)*$\")\n",
    "multi_file_pattern = re.compile(\".+(\\.png);.+\")\n",
    "\n",
    "# generates a list of every feature present for a specific row\n",
    "def extract_features(df, index):\n",
    "    features = []\n",
    "    for category in categories:\n",
    "        feature = df.loc[index, category]\n",
    "\n",
    "        if isinstance(feature, float):\n",
    "            if not math.isnan(feature):\n",
    "                features.append(feature)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if multi_label_pattern.match(feature):\n",
    "                features.extend(feature.split(';'))\n",
    "            elif multi_file_pattern.match(feature):\n",
    "                feature_files = feature.split(';')\n",
    "                for file in feature_files:\n",
    "                    filename = data_dir + 'images/' + file\n",
    "                    features.extend(extract_features_from_file(filename))\n",
    "                    \n",
    "            else:\n",
    "                filename = data_dir + 'images/' + feature\n",
    "                features.extend(extract_features_from_file(filename))\n",
    "\n",
    "    return features\n",
    "\n",
    "# returns a new dataframe with a link to the image, and the category class\n",
    "def process_index_file(df):      \n",
    "    processed_data = np.empty((len(df), 3))\n",
    "    processed_df = pd.DataFrame(data=processed_data, columns=['image', 'split', 'features'])\n",
    "    processed_df['image'] = pd.Series(dtype='str')\n",
    "    processed_df['split'] = pd.Series(dtype='str')\n",
    "    processed_df['features'] = pd.Series(dtype='object')\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        features = extract_features(df, index)\n",
    "        image = df.loc[index, 'image']\n",
    "        split = df.loc[index, 'split']\n",
    "        processed_df.at[index, 'image'] = image\n",
    "        processed_df.at[index, 'split'] = split\n",
    "        # This is so bad, need to figure out something better\n",
    "        processed_df.at[index, 'features'] = ','.join(map(str, [f'[{x}]' for x in features]))   \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63305/63305 [02:19<00:00, 454.93it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_data = process_index_file(index_frame)\n",
    "processed_data.drop(processed_data.columns[processed_data.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv(path_or_buf=data_dir + 'processed_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
