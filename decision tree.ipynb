{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "[ ] Run inferences on a different dataset and use activations to calculate one-hot concept vector for each image  \n",
    "[ ] Store prediction as label  \n",
    "[ ] Train decision tree  \n",
    "[ ] Get metrics for accuracy of decision tree predictions and actual alexnet predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "\n",
    "import skimage\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/hymenoptera_data'\n",
    "\n",
    "model_name = 'alexnet'\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = models.alexnet(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "\n",
    "# change classifier layer\n",
    "model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "        \n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 1.1326 Acc: 0.7336\n",
      "val Loss: 3.9669 Acc: 0.6013\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 4.6132 Acc: 0.5000\n",
      "val Loss: 1.4376 Acc: 0.8431\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.5821 Acc: 0.9344\n",
      "val Loss: 0.9623 Acc: 0.8954\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.7644 Acc: 0.8811\n",
      "val Loss: 0.7818 Acc: 0.8954\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.5376 Acc: 0.9016\n",
      "val Loss: 0.6345 Acc: 0.9020\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.3089 Acc: 0.9057\n",
      "val Loss: 0.6256 Acc: 0.8954\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.2510 Acc: 0.9221\n",
      "val Loss: 0.5694 Acc: 0.9085\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1350 Acc: 0.9590\n",
      "val Loss: 0.5930 Acc: 0.8889\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.2960 Acc: 0.9180\n",
      "val Loss: 0.5318 Acc: 0.9085\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1459 Acc: 0.9426\n",
      "val Loss: 0.5053 Acc: 0.9085\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.2204 Acc: 0.9262\n",
      "val Loss: 0.4806 Acc: 0.9150\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 0.9631\n",
      "val Loss: 0.4863 Acc: 0.8954\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1704 Acc: 0.9549\n",
      "val Loss: 0.4587 Acc: 0.9216\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1573 Acc: 0.9549\n",
      "val Loss: 0.4718 Acc: 0.8889\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0871 Acc: 0.9590\n",
      "val Loss: 0.5714 Acc: 0.8824\n",
      "\n",
      "Training complete in 0m 33s\n",
      "Best val Acc: 0.921569\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model, hist = train_model(\n",
    "        model, dataloaders_dict, criterion, optimizer_ft, \n",
    "        num_epochs=num_epochs, is_inception=(model_name==\"inception\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max pool, flattens, then normalizes activations\n",
    "def transform_activations(activations):\n",
    "    m = nn.MaxPool2d(2)\n",
    "    max_pool_outputs = m(activations)\n",
    "    flattened_outputs = max_pool_outputs.reshape((max_pool_outputs.shape[0], np.prod(max_pool_outputs.shape[1:])))\n",
    "    normalized_outputs = normalize(flattened_outputs)\n",
    "    return normalized_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns list of activations for a layer as well as the predicted class\n",
    "def extract_activations(model, data_loader):\n",
    "    print(\"test\")\n",
    "    activations = []\n",
    "    classes = []\n",
    "    \n",
    "    activation_dict = {}\n",
    "    \n",
    "    # setup for evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # define layer hook\n",
    "    def layer_hook(module, input, output):\n",
    "        layer_output = output.data.cpu()\n",
    "        activations.append(layer_output)\n",
    "    \n",
    "    # register hook on layer\n",
    "    handle = model.features[6].register_forward_hook(layer_hook) # register hook to access specific layer\n",
    "    \n",
    "    # do same thing for training set\n",
    "    for inputs, labels in data_loader['train']:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).data.cpu()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        classes.append(preds)\n",
    "\n",
    "    activations = torch.cat(activations, dim=0)\n",
    "    classes = torch.cat(classes, dim=0)\n",
    "    \n",
    "    activation_dict['train'] = (transform_activations(activations), classes)\n",
    "    \n",
    "    \n",
    "    # reset and do the same for val set\n",
    "    activations = []\n",
    "    classes = []\n",
    "    \n",
    "    # do same thing for val set\n",
    "    for inputs, labels in data_loader['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).data.cpu()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        classes.append(preds)\n",
    "    \n",
    "    activations = torch.cat(activations, dim=0)\n",
    "    classes = torch.cat(classes, dim=0)\n",
    "    \n",
    "    activation_dict['val'] = (transform_activations(activations), classes)\n",
    "\n",
    "    \n",
    "    handle.remove()\n",
    "    return activation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "activations = extract_activations(model, dataloaders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 13824)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations['train'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_activations(activations):\n",
    "    pca = PCA(n_components=100)\n",
    "    pca.fit(activations)\n",
    "    print(\"PCA score: %f\" % np.sum(pca.explained_variance_ratio_))\n",
    "    return pca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA score: 0.733243\n"
     ]
    }
   ],
   "source": [
    "pca = reduce_activations(activations['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 13824)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations['train'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acts = pca.transform(normalize(activations['train'][0]))\n",
    "val_acts = pca.transform(normalize(activations['val'][0]))\n",
    "Y_train = activations['train'][1]\n",
    "Y_val = activations['val'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load data (deserialize)\n",
    "with open('classifiers.pickle', 'rb') as handle:\n",
    "    classifiers = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = list(classifiers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_vectors(activations, classifiers):\n",
    "    predictions = []\n",
    "    num_concepts = len(classifiers.keys())\n",
    "    \n",
    "    # for each classifier, get the prediction\n",
    "    for clf in classifiers.items():\n",
    "        pred = clf[1][0].predict(activations)[np.newaxis]\n",
    "        pred = np.transpose(pred)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.hstack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_concept_vectors(train_acts, classifiers)\n",
    "X_val = get_concept_vectors(val_acts, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=10, max_depth=20)\n",
    "decision_tree = decision_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673202614379085"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_frame = pd.read_csv('dataset/broden1_227/label.csv')\n",
    "concept_names = labels_frame[labels_frame.number.isin(concepts)].name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trees/bees_ants_20_673.pdf'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(decision_tree, out_file=None, feature_names=concept_names, class_names=image_datasets['train'].classes)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"trees/bees_ants_20_673\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch2)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
